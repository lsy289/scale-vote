# ScaleVote (대규모 투표 처리 시스템)

## Overview
ScaleVote는 실시간으로 대량의 투표 데이터를 처리하고, 
사용자 요청에 대한 신뢰성 있는 데이터를 제공하는 대용량 트래픽을 위한 투표 시스템입니다. 
이 시스템은 100,000명의 사용자가 짧은 시간 내에 데이터를 전송하는 타임어택 이벤트를 전제로 하여 설계되었으며, 
비동기 처리 및 메시지 큐를 통한 안정적인 데이터 전송을 지원합니다. 
추후에는 클라우드 전환을 통한 유연한 인프라 확장, Redis 기반의 대기열 및 캐싱 도입, 데이터 신뢰성을 위한 데드레터 큐(Dead Letter Queue) 구현, 
외부 모니터링 시스템 연동 등의 기능을 추가하여 시스템 성능과 신뢰성을 더욱 강화할 계획입니다.

## 목차

- [개발 환경](#개발-환경)
- [프로젝트 설명](#프로젝트-설명)
  - [도메인](#도메인)
  - [애플리케이션](#애플리케이션)
- [주요 API 엔드포인트](#주요-api-엔드포인트)
- [아키텍처 구조](#아키텍처-구조)
- [데이터 파이프라인 설계](#데이터-파이프라인-설계)
- [개선포인트 (시간이 더 충분하다면 추가 및 변경하고 싶은 부분)](#개선포인트)

## 개발 환경

- **프레임워크**: Spring Boot 3, Spring Cloud Stream (Kafka)
- **언어**: Java 21
- **빌드 도구**: Gradle 8.6
- **데이터베이스**: MongoDB, PostgreSQL
- **비동기 메시지 브로커**: Kafka
- **테스트 데이터베이스**: TestContainers를 통한 실제 데이터베이스 통합 테스트

## 프로젝트 설명
### 도메인
- 투표 (Vote): 투표 데이터 및 선택한 옵션 정보를 관리

----

### 애플리케이션
- API Gateway: Spring Cloud Gateway를 통해 사용자 요청을 분산 처리합니다.
- Service A: 사용자 투표 데이터를 수신하고, Kafka를 통해 Service B로 데이터를 전송합니다.
- Service B: Kafka 메시지를 수신하고, MongoDB에 데이터를 저장한 후 가공하여 Service C로 전달합니다.
- Service C: Service B에서 전송된 데이터를 수신해 PostgreSQL에 저장하고, 특정 조건에 따라 알람 이벤트를 Kafka를 통해 전송합니다.

----

### 주요 API 엔드포인트
API Gateway
- POST /api/vote - 사용자의 투표 요청을 수신하고, 대기열에 추가하여 분산 처리합니다.

Service A
- POST /api/vote/data - Service A에서 Kafka를 통해 Service B로 데이터를 전송합니다.

Service B
- Kafka 수신 및 MongoDB 저장 - vote-topic에서 투표 데이터를 수신하고, MongoDB에 저장하여 Service C로 전송합니다.

Service C
- Kafka 수신 및 PostgreSQL 저장 - service-c-topic에서 데이터를 수신하여 가공 후 PostgreSQL에 저장하며, 특정 조건 충족 시 alert-topic에 알람 이벤트를 전송합니다.

----

### 아키텍처 구조
- 비동기 메시지 전송: Kafka를 사용하여 Service A에서 Service B, Service B에서 Service C로 데이터 전송을 수행하며, 이벤트 기반 아키텍처로 구성됩니다.
- 대기열 큐: API Gateway에서 대기열을 통해 트래픽을 분산하고, 서비스의 부하를 줄이는 구조입니다.

----

### 데이터 파이프라인 설계
대량의 트래픽을 효율적으로 처리하고 시스템 확장성을 높이기 위해 데이터 파이프라인을 구성할 예정입니다.

- 데이터 수집 및 적재: 사용자가 제출하는 투표 데이터를 Kafka를 통해 비동기로 수집하여 MongoDB, PostgreSQL에 적재합니다.
- 데이터 가공 및 처리: Service B와 Service C에서 필요에 따라 데이터를 가공하며, 특정 조건 충족 시 알람을 전송합니다.
- 실시간 이벤트 처리: Kafka를 통해 실시간 이벤트를 관리하여 사용자 요청에 대한 신뢰성 있는 데이터를 제공합니다.

----
### 개선포인트
#### 추후 시스템 확장성 및 성능을 높이기 위해 다음과 같은 고도화를 예정하고 있습니다.


1. **분산 처리 및 클라우드 전환**
   - AWS 또는 GCP 같은 클라우드 인프라로 전환하여 유연한 인프라 확장과 성능 최적화를 구현할 예정입니다.


2. **Redis 기반의 대기열 및 캐싱 도입**
    - Redis를 사용하여 데이터 캐싱과 대기열을 관리하고, 빠른 응답성과 확장성을 강화할 예정입니다. 


3. **Kafka 데드레터 큐 (DLQ) 구현**
    - 메시지 처리 실패 시 데드레터 큐(DLQ)를 통해 재처리 메커니즘을 추가하여 데이터 신뢰성을 보장할 계획입니다. 


4. **알람 로직 및 외부 모니터링 추가**
   - 특정 조건에 맞는 이벤트 발생 시 외부 알람 모니터링 시스템과 연동하여 시스템 장애를 사전에 예방합니다.


5. **성능 부하 테스트**
    - JMeter, Locust 등을 사용해 TPS 및 성능을 측정하고, 분산 처리에 최적화된 구조로 개선합니다.


6. **테스트 환경 개선**
    - TestContainers를 활용해 MongoDB 및 PostgreSQL을 실제 환경과 동일하게 구성하여 테스트하고, JaCoCo를 통해 테스트 커버리지를 높입니다.